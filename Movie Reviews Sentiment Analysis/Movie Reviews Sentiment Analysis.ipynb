{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhan-sukumar/NLP/blob/main/Movie%20Reviews%20Sentiment%20Analysis/Movie%20Reviews%20Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gf0u3uzd7oM"
      },
      "source": [
        "# Sentiment Analysis of Movie Reviews\n",
        "\n",
        "![](https://i.imgur.com/6Wfmf2S.png)\n",
        "\n",
        "> **Problem Statement**: Apply the TF-IDF technique to train ML models for sentiment analysis using data from the \"[Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)\" Kaggle.\n",
        "\n",
        "\n",
        "Outline:\n",
        "\n",
        "1. Download and Explore Dataset\n",
        "2. Implement the TF-IDF Technique\n",
        "3. Train baseline model\n",
        "4. Train & finetune different ML models\n",
        "\n",
        "\n",
        "\n",
        "Dataset: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw0pygCOefi9"
      },
      "source": [
        "## Download and Explore the Data\n",
        "\n",
        "Outline:\n",
        "\n",
        "1. Download Dataset from Kaggle\n",
        "2. Explore and visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPS8buEdtllZ"
      },
      "source": [
        "### Download Dataset from Kaggle\n",
        "\n",
        "- Read the \"Description\", \"Evaluation\" and \"Data\" sections on the Kaggle competition page carefully\n",
        "- Make sure to download the `kaggle.json` file from your [Kaggle account](https://kaggle.com/me/account) and upload it on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FnaGd60Zuxgg"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#viewing the current path\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PjvzlFu3SSm",
        "outputId": "d1dc5791-c113-4524-f14c-1eaac23855f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the current environment\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "metadata": {
        "id": "1K4fsseu3R_Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lcRhDakmuxEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057b2233-39b4-41a7-e12b-eb3471f29a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading sentiment-analysis-on-movie-reviews.zip to /content\n",
            "  0% 0.00/1.90M [00:00<?, ?B/s]\n",
            "100% 1.90M/1.90M [00:00<00:00, 179MB/s]\n"
          ]
        }
      ],
      "source": [
        "#downloading the dataset from kaggle\n",
        "!kaggle competitions download -c sentiment-analysis-on-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MdQqvmtvend_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34771088-9350-4094-cd15-fde75360f8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sentiment-analysis-on-movie-reviews.zip\n",
            "  inflating: data/sampleSubmission.csv  \n",
            "  inflating: data/test.tsv.zip       \n",
            "  inflating: data/train.tsv.zip      \n"
          ]
        }
      ],
      "source": [
        "#unzipping the zipped downloaded data\n",
        "!unzip sentiment-analysis-on-movie-reviews -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nEFLvfunenbr"
      },
      "outputs": [],
      "source": [
        "train_fname = '/content/data/train.tsv.zip'\n",
        "test_fname = '/content/data/test.tsv.zip'\n",
        "sub_fname = '/content/data/sampleSubmission.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVbujLQ9tpAb"
      },
      "source": [
        "### Explore and Visualize Data\n",
        "\n",
        "* Load the train, test, and submission files using Pandas\n",
        "* Explore rows, columns, sample values etc.\n",
        "* Visualize distribution of target columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oPwLSKsrvdTa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H2JenReXw7SI"
      },
      "outputs": [],
      "source": [
        "#reading the data\n",
        "raw_df= pd.read_csv(train_fname, sep='\\t') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4-cvRH3HenYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0169d328-c197-469a-a5f7-131c0ddf6b22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase  \\\n",
              "0         1           1  A series of escapades demonstrating the adage ...   \n",
              "1         2           1  A series of escapades demonstrating the adage ...   \n",
              "2         3           1                                           A series   \n",
              "3         4           1                                                  A   \n",
              "4         5           1                                             series   \n",
              "\n",
              "   Sentiment  \n",
              "0          1  \n",
              "1          2  \n",
              "2          2  \n",
              "3          2  \n",
              "4          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16af426e-f029-41e7-bf0c-774c124e82ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16af426e-f029-41e7-bf0c-774c124e82ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16af426e-f029-41e7-bf0c-774c124e82ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16af426e-f029-41e7-bf0c-774c124e82ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZwubETUvxTBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da127af8-ea76-42d2-ac21-812acff67c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n"
          ]
        }
      ],
      "source": [
        "raw_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EF3B9tjTxJVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083ec532-2398-4b70-f6a4-9c28c6d9121b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
              "       'A series of escapades demonstrating the adage that what is good for the goose',\n",
              "       'A series', 'A', 'series',\n",
              "       'of escapades demonstrating the adage that what is good for the goose',\n",
              "       'of',\n",
              "       'escapades demonstrating the adage that what is good for the goose',\n",
              "       'escapades',\n",
              "       'demonstrating the adage that what is good for the goose'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "raw_df.Phrase[:10].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l0Skd9KnxdjV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0a3c9ebd-380a-4d81-f7f9-756262ab1aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa0b352b-503c-4ca5-bc54-1ba4012edb1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa0b352b-503c-4ca5-bc54-1ba4012edb1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa0b352b-503c-4ca5-bc54-1ba4012edb1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa0b352b-503c-4ca5-bc54-1ba4012edb1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#loading test dataframe\n",
        "test_df = pd.read_csv(test_fname,sep='\\t')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uT_Dci92enWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "1e45d0d6-bbf0-41c2-e56f-4eb6d39e30c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "raw_df['Sentiment'].value_counts(normalize =True).sort_index().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sentiment labels are:\n",
        "\n",
        "0 - negative\n",
        "1 - somewhat negative\n",
        "2 - neutral\n",
        "3 - somewhat positive\n",
        "4 - positive. From the above plot, can see that the neutral is more than other reviews.\n",
        "\n",
        "The neutral reviews are more dominated and somewhat it is an imbalanced dataset"
      ],
      "metadata": {
        "id": "AM5VNbN5qfoI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYaRDixJen33"
      },
      "source": [
        "## Implement TF-IDF Technique\n",
        "\n",
        "![](https://i.imgur.com/5VbUPup.png)\n",
        "\n",
        "Outline:\n",
        "\n",
        "1. Learn the vocabulary using `TfidfVectorizer`\n",
        "3. Transform training and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3cu-meXuETm"
      },
      "source": [
        "#### Learn Vocabulary using `TfidfVectorizer `\n",
        "\n",
        "* Create custom tokenizer with stemming\n",
        "* Create a list of stop words\n",
        "* Configure and create `TfidfVectorizer `\n",
        "* Learn vocubulary from training set\n",
        "* View sample entries from vocabulary\n",
        "\n",
        "Countvectorizer vs TF-IIDF \n",
        "\n",
        "CountVectorizer only counts the number of times a word appears in the document, which results in biasing in favor of the most frequent words.\n",
        "\n",
        "TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides a numerical representation of how important a word is for statistical analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing and Stemming"
      ],
      "metadata": {
        "id": "HANfQmowUWEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u7pWYRHnzUWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da28c2b2-0ad8-4053-b270-d87f9adffb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ag_lyI8mzbqE"
      },
      "outputs": [],
      "source": [
        "#stemming\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4vzkmwVG0GGE"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DxZWPPfE0FeN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1838aba5-788d-43f7-ae73-a0a3e3549cf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'love'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "stemmer.stem('loving')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ffPOWbhdd7oP"
      },
      "outputs": [],
      "source": [
        "#Stemming the sentence after tokenized and punctuations are removed \n",
        "def tokenize(text):\n",
        "  return [stemmer.stem(token) for token in word_tokenize(text) if token.isalpha()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Tp3P0zaw0ATc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6987411f-2888-49da-b446-415027f02dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'love', 'this', 'stori']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tokenize('i am loving this stories !')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words"
      ],
      "metadata": {
        "id": "XAGiaKchUbgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "english_stopwords = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCt8iEKBUdnx",
        "outputId": "22418689-ff5d-46c9-cc98-8cb803a9bb37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(english_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llELSPMTVZeU",
        "outputId": "3d25493d-a37d-456e-a00f-37960c74575a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the stop words contains negative emotional words like didn't, doesn't. These words are more important for setntiment analysis. so filtered out rest of the stop words for stop words removal "
      ],
      "metadata": {
        "id": "E2H1nT8DVlIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_stopwords = english_stopwords[:115]\n",
        "print(selected_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIsSlcHDVkzf",
        "outputId": "65d81c3d-5373-4da6-bedd-14343df8e643"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "jPGIvRA4TvJq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aggX4uwmeswS"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UWS0NJkk0Z2p"
      },
      "outputs": [],
      "source": [
        "vectorizer= TfidfVectorizer(tokenizer=tokenize, stop_words =selected_stopwords,ngram_range=(1,2),max_features=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Tu_garEvesta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "5d4bd1e8-760d-4911-8849-e551b425e44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'onc', 'ourselv', 'themselv', 'whi', 'yourselv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_features=2000, ngram_range=(1, 2),\n",
              "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
              "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
              "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
              "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
              "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
              "                            'itself', ...],\n",
              "                tokenizer=<function tokenize at 0x7ff88db8e950>)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=2000, ngram_range=(1, 2),\n",
              "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
              "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
              "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
              "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
              "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
              "                            &#x27;itself&#x27;, ...],\n",
              "                tokenizer=&lt;function tokenize at 0x7ff88db8e950&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=2000, ngram_range=(1, 2),\n",
              "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
              "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
              "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
              "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
              "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
              "                            &#x27;itself&#x27;, ...],\n",
              "                tokenizer=&lt;function tokenize at 0x7ff88db8e950&gt;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#ftting the vectorizer to learn the frequency of occurence of words in trianing data\n",
        "vectorizer.fit(raw_df.Phrase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Xl-NWRL4esq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a20515a-494c-48db-f383-f3ee89e5ee80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['abandon', 'abil', 'abl', 'abov', 'absolut', 'absorb', 'abstract',\n",
              "       'absurd', 'abus', 'accent', 'accept', 'access', 'accomplish',\n",
              "       'accur', 'ach', 'achiev', 'across', 'act', 'action', 'action film',\n",
              "       'action movi', 'action sequenc', 'actor', 'actress', 'actual',\n",
              "       'ad', 'adam', 'adam sandler', 'adapt', 'add', 'addit', 'adequ',\n",
              "       'admir', 'admit', 'adolesc', 'adult', 'adventur', 'affair',\n",
              "       'affect', 'afraid', 'age', 'ago', 'ahead', 'aim', 'aimless', 'air',\n",
              "       'alien', 'aliv', 'allen', 'allow', 'almost', 'alon', 'along',\n",
              "       'alreadi', 'also', 'altern', 'although', 'alway', 'amateurish',\n",
              "       'amaz', 'ambigu', 'ambit', 'ambiti', 'america', 'american',\n",
              "       'among', 'amount', 'amus', 'analyz', 'angel', 'angst', 'ani',\n",
              "       'anim', 'ann', 'annoy', 'anoth', 'answer', 'anyon', 'anyth',\n",
              "       'apart', 'appar', 'appeal', 'appear', 'appli', 'appreci',\n",
              "       'approach', 'appropri', 'area', 'argu', 'argument', 'around',\n",
              "       'arriv', 'art', 'artifici', 'artist', 'ask', 'aspect', 'aspir',\n",
              "       'assassin', 'associ'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N83nLs4juO67"
      },
      "source": [
        "### Transform Training & Test Data\n",
        "\n",
        "* Transform phrases from training set\n",
        "* Transform phrases from test set\n",
        "* Look at some example values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "B6WXWiQzuOcX"
      },
      "outputs": [],
      "source": [
        "#transforming trianing data\n",
        "inputs = vectorizer.transform(raw_df.Phrase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0BDzHuBbuPSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a820ca7-e738-467e-987e-91db819a5185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sEnfZpS83eUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98934c7-3c7f-4f7c-cd32-aa361db5ff8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.27620188,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.33022325, 0.29314979, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "inputs.toarray()[0][:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QLngc6g5yspe"
      },
      "outputs": [],
      "source": [
        "#transforming the test data \n",
        "test_inputs= vectorizer.transform(test_df.Phrase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z9JRRv_Q4QNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae840bb-0491-4860-8232-85fd451e586f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66292, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "test_inputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwLM4r3EetEK"
      },
      "source": [
        "## Train Baseline Model\n",
        "\n",
        "1. Split training and validation sets\n",
        "2. Train logistic regression model\n",
        "3. Study predictions on sample phrases\n",
        "4. Make predictions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAZkydfs4wrX"
      },
      "source": [
        "### Split Training and Validation Sets\n",
        "\n",
        "Tip: Don't use a random sample for validation set. We are taking first 110000 rows for traning and remaining for validation, so we can measure how the model performed on remaining 46060 rows of validation set which is not seen and not taking random sample helps to make a model see only first 110000 but not random 110000 rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kABFLf8Qu5OE",
        "outputId": "26366ad7-10dc-4bac-ce8f-9970afba6b9a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_9wZLI9i4rlB"
      },
      "outputs": [],
      "source": [
        "Train_size = 110_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FnALsBHr4aQt"
      },
      "outputs": [],
      "source": [
        "#setting first 11000 rows as x train and y train\n",
        "train_inputs = inputs[:Train_size]\n",
        "train_targets = raw_df.Sentiment[:Train_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "EF8dHyrF4S3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e908182f-459d-41ea-e8eb-8f6c36e494f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((110000, 2000), (110000,))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "train_inputs.shape , train_targets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "JXg0N5Tset2n"
      },
      "outputs": [],
      "source": [
        "#setting next 46060 rows for valdiation\n",
        "val_inputs = inputs[Train_size:]\n",
        "val_targets = raw_df.Sentiment[Train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5-VO-Ad25CUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12600f69-f965-484d-eaa8-27e03030b901"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((46060, 2000), (46060,))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "val_inputs.shape, val_targets.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHoTrGTM5Bo9"
      },
      "source": [
        "### Logistic Regression Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "jEHCuRAt7swN"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7klXZoh-7st2"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "THyNzV9J7srO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "be197c2a-1ff6-4bbd-8a43-6029423c61ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "lr.fit(train_inputs,train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qQ0HAnwP8k1S"
      },
      "outputs": [],
      "source": [
        "#prediction on training data\n",
        "train_pred = lr.predict(train_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "TFXjhxfS70Ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57547193-e0e3-42a2-f49d-195a4948842d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1\n",
              "1         2\n",
              "2         2\n",
              "3         2\n",
              "4         2\n",
              "         ..\n",
              "109995    1\n",
              "109996    0\n",
              "109997    1\n",
              "109998    0\n",
              "109999    2\n",
              "Name: Sentiment, Length: 110000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "train_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lT_-tby27so2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b8be8d-090b-4576-e6d4-02b90ebbfd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6381818181818182\n"
          ]
        }
      ],
      "source": [
        "#accuracy on training data prediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_pred_accuracy = accuracy_score(train_targets,train_pred)\n",
        "print(train_pred_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on validation data\n",
        "val_pred = lr.predict(val_inputs)\n",
        "val_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZg5rjCJxngW",
        "outputId": "68ea3f9c-4caf-482a-951b-dc08f30db2f9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, ..., 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy on validation dataset\n",
        "val_pred_accuracy = accuracy_score(val_targets,val_pred)\n",
        "print(val_pred_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLh_UWWjxnTV",
        "outputId": "cef27809-fb3e-46f5-a8be-c94d4d22557a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5795049934867564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction On Test Data"
      ],
      "metadata": {
        "id": "-hlQr77z5e5R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jz8W9Nnce31g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1aeabe6-ed1e-43fd-da21-6594201182c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 2, ..., 2, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "lr.predict(test_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kne2rQq8qL0"
      },
      "source": [
        "## Train & Finetune Different ML Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ERFb1zswhp"
      },
      "source": [
        "### RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "kN-yZN12e4Yz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1b65e635-5c75-4682-f712-abc3ab933e24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "#fitting and training the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier  = RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
        "rf_classifier.fit(train_inputs,train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "X8f6t6wge4WV"
      },
      "outputs": [],
      "source": [
        "train_pred_rf = rf_classifier.predict(train_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "lig2PXUCAfqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924f3f7d-4620-435f-d736-fe0c7b2a62b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7902727272727272\n"
          ]
        }
      ],
      "source": [
        "train_pred_acc_rf = accuracy_score(train_targets,train_pred_rf)\n",
        "print(train_pred_acc_rf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on validation set\n",
        "val_pred_rf = rf_classifier.predict(val_inputs)"
      ],
      "metadata": {
        "id": "QLKMmVmyGU5X"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred_acc_rf = accuracy_score(val_targets,val_pred_rf)\n",
        "print(val_pred_acc_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSixbi71GUlj",
        "outputId": "5b012d8c-3afe-4bc9-b850-bbcc3265cb7a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.560790273556231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "report=classification_report(val_targets,val_pred_rf)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKyRPVGUKBGY",
        "outputId": "422bb7bf-c577-41c6-a5d8-d5d7c27b0da8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.10      0.16      2135\n",
            "           1       0.47      0.29      0.36      8613\n",
            "           2       0.62      0.83      0.71     22740\n",
            "           3       0.45      0.41      0.43      9708\n",
            "           4       0.43      0.10      0.16      2864\n",
            "\n",
            "    accuracy                           0.56     46060\n",
            "   macro avg       0.47      0.35      0.36     46060\n",
            "weighted avg       0.53      0.56      0.52     46060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the accuracy score on training data and validation data we can see that the training accuracy is 0.79 and validation accuracy is 0.56. From this we can see that the model is somewhat overfitted but we can use different hyperparamter tuning methods to reduce overfitting."
      ],
      "metadata": {
        "id": "_8YZY85MIdk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "qcGYONseNcvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "nAkDic_FJdOm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = MultinomialNB()"
      ],
      "metadata": {
        "id": "XpK27SRUNliG"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the data\n",
        "nb_model.fit(train_inputs,train_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Fr38uovzNosg",
        "outputId": "7de4e727-b769-4bc9-ba3d-6a82bbf87d0f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on trian data\n",
        "train_pred_nb = nb_model.predict(train_inputs)"
      ],
      "metadata": {
        "id": "WIkIhpg2Nt7p"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_acc_nb = accuracy_score(train_targets,train_pred_nb)\n",
        "print(train_pred_acc_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ19psRkN97c",
        "outputId": "3f7f5bf4-cba4-47b1-9662-7855d54c1d59"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5848363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on validation data\n",
        "val_pred_nb = nb_model.predict(val_inputs)"
      ],
      "metadata": {
        "id": "AoMZ-kR_OH-S"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score of validation data prediction\n",
        "val_pred_acc_nb = accuracy_score(val_targets,val_pred_nb)\n",
        "print(val_pred_acc_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P0RnEOHOSfj",
        "outputId": "491cd2b7-fea5-440c-90ff-0ada1db21757"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5429005644811116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While using Multinomial Naives bayes classifer, we achieved an training accuracy of 0.58 and accuracy on validation set is 0.54, In this the model is not overfitted but we can use different hyperparameters tuning methods to increase the accuracy.\n",
        "\n",
        "\n",
        "#### From all three models, conclusively Logistic Regression model was performed better "
      ],
      "metadata": {
        "id": "haLRyCZNO2kQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}