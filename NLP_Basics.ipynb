{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwFF7pMz8OR0yPdw6eZWzL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhan-sukumar/NLP/blob/main/NLP_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LeiZEPnHGw01"
      },
      "outputs": [],
      "source": [
        "train_x = ['i love the book','this is a great book', 'the fit is great','i love the shoes']\n",
        "train_y = ['Books','Books','Clothing','Clothing']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words\n",
        "\n",
        "Bag of words convert words into vector"
      ],
      "metadata": {
        "id": "IqLh2WpDP4NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing countvectorizer for bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "#countvectorizer is non binanry, so if we want binary output we can give binary =True\n",
        "vectorizer = CountVectorizer(binary=True) \n",
        "train_x_vectors = vectorizer.fit_transform(train_x)\n"
      ],
      "metadata": {
        "id": "XGRNCekcG_6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(train_x_vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd5f3Q0-IQrB",
        "outputId": "dcca9260-b902-41f0-e610-353ec096ed92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book' 'fit' 'great' 'is' 'love' 'shoes' 'the' 'this']\n",
            "[[1 0 0 0 1 0 1 0]\n",
            " [1 0 1 1 0 0 0 1]\n",
            " [0 1 1 1 0 0 1 0]\n",
            " [0 0 0 0 1 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building a simple classifier model\n",
        "from sklearn import svm\n",
        "clf_svm =  svm.SVC(kernel = 'linear')\n",
        "\n",
        "clf_svm.fit(train_x_vectors,train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "G3BNbOysIYUj",
        "outputId": "c7994512-b17e-4415-fd97-473723e36298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model\n",
        "test_y = vectorizer.transform(['i love the shoes', 'book is good to read'])\n",
        "\n",
        "\n",
        "clf_svm.predict(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBTnaqGNKbHc",
        "outputId": "eaf51d42-d24b-4b3f-a290-0d2473b46616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Clothing', 'Books'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Vectors\n",
        "\n",
        "Words vectors capture the semantic meaning of words into vectors. The semantic meaning of a word refers to its underlying meaning or the concepts, ideas, or associations it represents.\n",
        "\n",
        " Ex- red, blue, green are colour so if the sentence contain words red or blue or green it consider those words have same association and by taking one word, it try to find the context of the words in the sentence "
      ],
      "metadata": {
        "id": "ZDLrNG7ZQAij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_md\n"
      ],
      "metadata": {
        "id": "xKp97lSAK8SH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15297b8a-5701-421e-906c-fa2316f5536d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-28 15:19:49.093609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "5DfJ6Cd6VI8r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzeaVqC_-4hr",
        "outputId": "ad8a14d1-16db-4d25-baf9-f276685b565a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i love the book', 'this is a great book', 'the fit is great', 'i love the shoes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating vectors\n",
        "docs = [ nlp(text) for text in train_x]\n",
        "print(docs[0].vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlkpGSGJCjzD",
        "outputId": "555f8abe-b1cb-4cfd-bd9b-f5e0b90e0afe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.9804751e-01 -1.7059250e+00 -9.0664995e-01 -4.5425000e+00\n",
            " -1.1165801e+00 -2.9151249e+00  3.1752450e+00  4.0887251e+00\n",
            " -3.4474750e+00  2.3840599e+00  6.4857249e+00  2.3083498e+00\n",
            " -8.6464500e+00  2.0437698e+00  2.2699749e+00 -1.0261000e+00\n",
            "  4.0915399e+00 -7.4801493e-01  1.1435002e-01 -1.9810501e+00\n",
            "  1.3855026e+00  1.7070000e+00 -2.9752648e+00 -1.9328325e+00\n",
            " -1.4255500e+00 -2.0426226e+00 -3.7064652e+00 -4.3784651e-01\n",
            " -2.0860374e+00  4.4308500e+00 -1.0481000e+00 -7.8117514e-01\n",
            " -1.6870000e+00  1.9781501e+00  1.4894226e+00 -2.8325254e-01\n",
            " -1.4800999e+00  1.4303375e+00  2.6068749e+00 -1.3935680e+00\n",
            " -4.5071498e-01  1.8592875e+00  6.0194993e-01 -2.0355899e+00\n",
            "  5.3853750e+00  3.3568425e+00 -2.6558499e+00 -2.5876875e+00\n",
            " -4.1877502e-01  1.1819749e+00 -1.0135007e-01 -1.6391747e+00\n",
            " -7.5115502e-01 -2.4396350e+00 -5.0018353e+00  4.4182479e-02\n",
            " -1.1361099e+00  3.4045234e+00  4.4069252e+00  1.5867125e+00\n",
            "  7.3212752e+00 -6.2377250e-01 -3.5406952e+00 -1.5487249e+00\n",
            " -2.7915027e+00  4.5692497e-01 -2.8675752e+00 -2.1574497e+00\n",
            "  3.5327253e+00  2.9429674e+00 -3.0028498e+00  4.0561576e+00\n",
            " -2.2131751e+00 -2.7301099e+00  2.2525599e+00  6.7574859e-02\n",
            " -2.9405074e+00  1.8029499e+00 -1.1789126e+00 -2.1746502e+00\n",
            " -2.1985504e-01  1.1351575e+00  3.9773331e+00 -1.4294751e+00\n",
            "  2.7083826e-01  2.8169625e+00  3.3689499e+00 -3.6275029e-02\n",
            " -6.6733754e-01 -2.0622499e+00  5.5217499e-01  2.1563876e+00\n",
            "  5.8253503e+00 -5.5494246e+00 -3.5856503e-01 -1.6503401e+00\n",
            " -1.3458250e+00 -1.4840007e-01  1.7622524e+00 -9.1479999e-01\n",
            "  2.1465900e+00  4.4622073e+00  3.2821400e+00  1.8457750e+00\n",
            " -1.8648493e-01  9.6283495e-01 -1.4834499e+00  4.0102500e-01\n",
            " -2.9797997e+00  7.9937494e-01  2.4522400e+00 -1.5166250e+00\n",
            " -3.7715238e-01  2.3985500e+00  3.3255002e-01  1.7986224e+00\n",
            " -6.8490005e-01 -5.1091760e-01 -1.8716326e+00 -8.0151993e-01\n",
            " -1.2196251e+00 -2.4377999e+00 -8.4822536e-01  4.4465375e+00\n",
            "  1.9551001e+00 -4.5647252e-01  1.1451000e+00 -2.7702999e+00\n",
            " -5.0074500e-01 -1.2053250e+00 -5.6294746e+00  1.9835000e+00\n",
            " -2.7191000e+00 -1.5045950e+00  6.9217503e-01  2.5230401e+00\n",
            " -2.1575000e+00 -1.4835875e+00  3.3636250e+00 -1.8662750e+00\n",
            " -2.0677674e+00  1.4370599e+00  1.0521392e+00  2.1033750e+00\n",
            " -2.1464827e+00  5.6450999e-01  5.3212500e-01 -8.3847724e-02\n",
            " -6.6377509e-01  6.8043244e-01 -2.0621850e+00  2.8536501e+00\n",
            " -1.7352247e+00 -2.8443000e+00 -5.3201753e-01  8.3302242e-01\n",
            "  3.7822717e-01  9.0502751e-01 -9.2559004e-01  2.6364100e-01\n",
            " -2.1059022e+00 -4.7094274e+00 -2.3757493e-01  1.3409747e-01\n",
            " -1.4695925e+00  1.1836300e+00 -1.7678249e+00 -2.0474751e+00\n",
            " -3.1015801e+00 -2.7474751e+00  2.3939500e+00  2.9119998e-01\n",
            " -6.4154994e-01  2.9983025e+00  2.3853002e+00 -3.8257499e+00\n",
            "  4.6561250e-01  2.4625850e+00 -4.1938251e-01  6.9829524e-01\n",
            " -7.1579993e-01 -1.4624953e-02  3.2372375e+00 -3.2502999e+00\n",
            "  4.5349836e-02  4.1063027e+00 -2.2001500e+00 -1.6467290e+00\n",
            "  3.1262751e+00  1.4225700e+00  3.6304951e-02  1.4041975e+00\n",
            " -1.5605751e+00  2.3753252e+00  2.6392999e+00 -1.5464250e+00\n",
            " -5.9728498e+00  1.9010249e+00 -1.8664751e+00  5.6060200e+00\n",
            " -9.5827496e-01 -1.9006126e+00 -4.8451276e+00 -5.8231246e-01\n",
            " -7.2317505e-01 -2.2110374e+00  8.1549001e-01 -1.0414025e+00\n",
            "  1.9058951e+00 -3.8605497e+00  3.5286000e+00  1.3662599e+00\n",
            "  2.2550497e+00  2.5063176e+00 -2.7124995e-01  1.9068251e+00\n",
            " -2.3303626e+00 -3.5958242e-01  7.9588258e-01 -1.6820974e+00\n",
            " -3.7828848e+00  2.2385600e+00 -2.3069249e-01  3.8866749e+00\n",
            " -2.9949999e+00 -7.2774887e-02 -5.2936137e-01  2.3862777e+00\n",
            "  2.7844000e+00  2.0868599e+00 -1.0202500e+00 -6.6188755e+00\n",
            "  2.5358500e+00  2.3292500e-01 -1.5609975e+00  1.4913775e+00\n",
            "  4.9717754e-01  6.1425052e+00 -9.3077004e-01 -1.0970299e+00\n",
            " -3.2835951e+00 -4.0366502e+00  2.8092499e+00  5.4461503e-01\n",
            "  5.1136999e+00 -4.7508508e-01 -3.0958500e+00 -1.6869251e+00\n",
            "  5.5714927e+00 -5.8892751e-01 -2.1862252e+00  7.2488189e-04\n",
            " -5.1041250e+00 -2.0981116e+00 -3.4806490e-01 -1.5959325e+00\n",
            " -4.2672509e-01  1.1591926e+00 -3.7716749e+00  2.1917500e+00\n",
            "  2.8775399e+00  3.8451598e+00  4.2834749e+00  2.1570098e+00\n",
            "  2.5055449e+00 -1.2231750e+00  4.1285264e-01  1.1988211e+00\n",
            " -4.9739499e+00  1.0778250e+00  4.2271227e-01 -3.8091974e+00\n",
            " -3.7465799e+00 -1.0162874e+00 -1.5726924e+00 -3.8487256e-01\n",
            "  2.0939450e+00 -3.7680500e+00  2.6195997e-01  2.4638376e+00\n",
            " -1.9473826e+00 -1.5511725e+00  3.0020747e+00  4.0775223e+00\n",
            "  4.7141755e-01 -1.4983499e-01  2.5353000e+00  2.0879149e+00\n",
            " -1.3202243e-01 -2.3845255e-01  4.0010076e+00  1.6600013e-02\n",
            "  4.4546151e+00 -1.3000700e+00 -2.6352043e+00  1.1399500e+00\n",
            "  1.8315576e+00 -2.9688001e+00 -7.6453247e+00  8.4300494e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving all the vectors separately as value, since it is a spacy tokens.\n",
        "train_x_wv = [x.vector for x in docs] "
      ],
      "metadata": {
        "id": "b5g82v7PEEGC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building a simple model on word vectors\n",
        "\n",
        "from sklearn import svm\n",
        "clf_svm_wv =  svm.SVC(kernel = 'linear')\n",
        "\n",
        "clf_svm_wv.fit(train_x_wv,train_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "p2nsn036CstC",
        "outputId": "fa195ba0-6731-47fa-ba3a-dd7cfb392c99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "text_x = ['I love the slipper','I hate the story', 'i like the earings'] \n",
        "text_docs_wv = [nlp(text) for text in text_x]\n",
        "text_x_wv = [x.vector for x in text_docs_wv]\n",
        "\n",
        "clf_svm_wv.predict(text_x_wv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwW78Co7EtYW",
        "outputId": "5f1c528c-d613-4503-c9f7-0414d2fe269f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Clothing', 'Books', 'Clothing'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantage:\n",
        "\n",
        "slipper,story,hate,like and earings are not in the training, but it predicted as clothing and books correctly, since spacy trained the english words semantic.\n",
        "\n",
        "Disadvatage: word vectors cannot provide semantic based on context of text. ex: write a check and let me check is different "
      ],
      "metadata": {
        "id": "sBcn36RoGODF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming and Lematisation"
      ],
      "metadata": {
        "id": "tQ34rFDvQo4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') # tokeniser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udmucpLKE2dM",
        "outputId": "b1b0426b-db37-4c70-8ff5-939e77966cb7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "phrase = 'reading the history'\n",
        "\n",
        "#tokenize the words\n",
        "tokenized_words = word_tokenize(phrase)\n",
        "print(tokenized_words)\n",
        "\n",
        "#stemming\n",
        "stemmed = []\n",
        "for word in tokenized_words:\n",
        "  stemmed.append(stemmer.stem(word))\n",
        "\n",
        "print(stemmed)\n",
        "\n",
        "#finaly joining\n",
        "new = \" \".join(stemmed)\n",
        "print(new)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toy8FG22TEuV",
        "outputId": "bebc36c6-bb4c-4ded-df38-1601c4093f46"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['reading', 'the', 'history']\n",
            "['read', 'the', 'histori']\n",
            "read the histori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lematization\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "phrase = 'reading the history'\n",
        "\n",
        "#tokenize the words\n",
        "tokenized_words = word_tokenize(phrase)\n",
        "print(tokenized_words)\n",
        "\n",
        "#lematization\n",
        "lemmatized = []\n",
        "for word in tokenized_words:\n",
        "  lemmatized.append(lemmatizer.lemmatize(word, pos ='v'))\n",
        "\n",
        "print(lemmatized)\n",
        "\n",
        "#finaly joining\n",
        "new = \" \".join(lemmatized)\n",
        "print(new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYyrji0qUOnr",
        "outputId": "ad66f85f-8132-4696-a2d6-c4e116510871"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['reading', 'the', 'history']\n",
            "['read', 'the', 'history']\n",
            "read the history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StopWord Removal"
      ],
      "metadata": {
        "id": "KsZdEIknX8N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english') #having 179 stopwords\n",
        "\n",
        "phrase = 'Here is an example sentence demonstrating the removal of stopwords'\n",
        "\n",
        "#tokenize the sentence\n",
        "tokenized = word_tokenize(phrase)\n",
        "\n",
        "#stop word removal\n",
        "stop_word_removed = []\n",
        "for word in tokenized:\n",
        "  if word not in stop_words:\n",
        "    stop_word_removed.append(word)\n",
        "\n",
        "new = \" \".join(stop_word_removed)\n",
        "print(new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YhlxuW5WSwn",
        "outputId": "f627f85b-645a-495c-e5d8-f05c46d3e56f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here example sentence demonstrating removal stopwords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEXTBLOB PACKAGE"
      ],
      "metadata": {
        "id": "iu-F8pR2Z-8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "qDUqdzNMcI9Z",
        "outputId": "f7ec5318-6779-4bca-b112-e1a7c4c8c8bf"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-bec4ba3f7ac1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m textblob.download_corpora\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "phrase = 'This is an example'\n",
        "\n",
        "blob = TextBlob(phrase)\n",
        "\n",
        "#spelling correction\n",
        "phrase_2 = 'iti is a_n examplee'\n",
        "blob_2 = TextBlob(phrase_2)\n",
        "print(blob_2.correct())\n",
        "\n",
        "#sentiment analyser\n",
        "phrase_3 = 'i love this book'\n",
        "blob_3 = TextBlob(phrase_3)\n",
        "print(blob_3.sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y9mosh9YX0C",
        "outputId": "c0e3839d-2b61-4ffa-b74e-588c92a4d937"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is an example\n",
            "Sentiment(polarity=0.5, subjectivity=0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb9U6fs-audV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}